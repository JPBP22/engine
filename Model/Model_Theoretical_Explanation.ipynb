{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARP (Weighted Approximate-Rank Pairwise) Theoretical Explanation\n",
    "\n",
    "WARP (Weighted Approximate-Rank Pairwise) loss is a loss function used in collaborative filtering models for ranking tasks, such as recommendation systems. The main idea behind WARP is to maximize the rank of the positive item relative to the negative items by sampling the negative items in a way that is likely to produce informative updates to the model parameters.\n",
    "\n",
    "The loss function is defined as follows:\n",
    "\n",
    "$L_{i,j} = sum_{j'=1}^{j-1} max(0, 1 - s(i,j) + s(i,j'))$\n",
    "\n",
    "where:\n",
    "\n",
    "- i is the user\n",
    "- j is the positive item\n",
    "- j' is a negative item\n",
    "- s(i,j) is the predicted score of item j for user i\n",
    "\n",
    "The sampling is done in a way that gives preference to the negative items that are the hardest to rank higher than the positive item, i.e., the ones that have the highest predicted score.\n",
    "\n",
    "The code you provided is using the WARP loss function in a matrix factorization model with 30 latent factors. The run_model function is fitting the model to the training data train and specifying various parameters such as the number of epochs and the number of jobs to use for parallel processing.\n",
    "\n",
    "After fitting the model, the code computes the precision and AUC scores on the training and test sets using the precision_at_k and auc_score functions, respectively. These metrics are commonly used to evaluate the performance of recommendation systems.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR loss model Theoretical Explanation\n",
    "\n",
    "BPR (Bayesian Personalized Ranking) loss is another loss function commonly used in matrix factorization-based collaborative filtering models for ranking tasks, such as recommendation systems. The main idea behind BPR is to maximize the pairwise ranking of items based on users' implicit feedback, such as clicks or purchases, by modeling the preference of each user for the items they have interacted with.\n",
    "\n",
    "$L_{i,j,j'} = -ln(sigma(s(i,j) - s(i,j')))$\n",
    "\n",
    "where:\n",
    "\n",
    "- i is the user\n",
    "- j is a positive item\n",
    "- j' is a negative item\n",
    "- s(i,j) is the predicted score of item j for user i\n",
    "- sigma is the sigmoid function\n",
    "\n",
    "The loss function encourages the model to assign a higher score to the positive item $j$ than the negative item $j'$ for user $i$.\n",
    "\n",
    "The code you provided is using the BPR loss function in a matrix factorization model with 30 latent factors. The run_model function is fitting the model to the training data train and specifying various parameters such as the number of epochs and the number of jobs to use for parallel processing.\n",
    "\n",
    "After fitting the model, the code computes the precision and AUC scores on the training and test sets using the precision_at_k and auc_score functions, respectively. These metrics are commonly used to evaluate the performance of recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
