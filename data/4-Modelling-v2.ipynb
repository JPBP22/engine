{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3b3146",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d1586",
   "metadata": {},
   "source": [
    "The purpose of this Notebook is to construct our recommendation system that will generate both user recommendations and similar item recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import sparse\n",
    "from lightfm import LightFM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from scipy.spatial import distance\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "from resources import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa758b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run resources.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33e046",
   "metadata": {},
   "source": [
    "Load `recdata.csv` with user and owned games ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88235905",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recdata = pd.read_csv('recdata.csv', index_col=0)\n",
    "recdata = recdata.rename(columns = {'variable':'id', 'value': 'owned'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f68d5",
   "metadata": {},
   "source": [
    "Load file with game details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba003ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamesdata = pd.read_csv('gamesdata.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11694f4d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ef7c8",
   "metadata": {},
   "source": [
    "Our approach involves generating an interactions matrix from the user-item data. This can be achieved through implementation of the create_interaction_matrix function, which is located in resources.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = create_interaction_matrix(df = recdata,\n",
    "                                         user_col = 'uid',\n",
    "                                         item_col = 'id',\n",
    "                                         rating_col = 'owned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a5c9d",
   "metadata": {},
   "source": [
    "Manually split interactions matrix into training set and test set for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64608c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2de7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int((80/100)*len(interactions))\n",
    "test_num = len(interactions) - train_num\n",
    "\n",
    "print(\"{} users in training set.\".format(train_num))\n",
    "print(\"{} users in test set.\".format(test_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sets\n",
    "train = interactions[:55422]\n",
    "test = interactions[55422:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecc5b9",
   "metadata": {},
   "source": [
    "### User Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a41c97",
   "metadata": {},
   "source": [
    "A dictionary will be made to pair users with a counter ID. This will be achieved by utilizing the create_user_dict function, which is present in resources.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70eaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a user dictionary utilizing the create_user_dict helper function\n",
    "user_dict = create_user_dict(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63513245",
   "metadata": {},
   "source": [
    "### Item Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eebce9",
   "metadata": {},
   "source": [
    "A dictionary will be generated to match every game ID with its corresponding title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a game dictionary through utilization of the create_item_dict helper function\n",
    "games_dict = create_item_dict(gamesdata, 'id', 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5843d",
   "metadata": {},
   "source": [
    "### Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56390f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enhance the efficiency of computations, we will convert the interaction into a sparse matrix. \n",
    "# For the trainset, we will use the sparse.csr_matrix() function. However, for the test set, we have \n",
    "# to add more rows to match the number of rows in the train set, due to a known issue.\n",
    "\n",
    "train_sparse = sparse.csr_matrix(train.values)\n",
    "\n",
    "N = train.shape[0] # Total rows in Train set\n",
    "n, m = test.shape # Rows and columns in Test set\n",
    "z = np.zeros([(N - n), m]) # Create blank rows with m columns to fulfill missing rows\n",
    "test = np.vstack((test, z)) # Stack Test vertically over the empty users' rows\n",
    "test_sparse = sparse.csr_matrix(test) # Convert back to sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97a929",
   "metadata": {},
   "source": [
    "## Modelling using LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1400a2a",
   "metadata": {},
   "source": [
    "WARP Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "mf_model_warp = run_model(train, 30, 'warp', 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4297fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "train_precision = np.mean(precision_at_k(mf_model_warp, train_sparse, k=10))\n",
    "test_precision = np.mean(precision_at_k(mf_model_warp, test_sparse, k=10))\n",
    "print('Precision: train {:.2f}, test {:.2f}.'.format(train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "train_auc = np.mean(auc_score(mf_model_warp, train_sparse))\n",
    "test_auc = np.mean(auc_score(mf_model_warp, test_sparse))\n",
    "print('AUC: train {:.2f}, test {:.2f}.'.format(train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51531892",
   "metadata": {},
   "source": [
    "BPR Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model_bpr = run_model(train, 30, 'bpr', 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = np.mean(precision_at_k(mf_model_bpr, train_sparse, k=10))\n",
    "test_precision = np.mean(precision_at_k(mf_model_bpr, test_sparse, k=10))\n",
    "print('Precision: train {:.2f}, test {:.2f}.'.format(train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = np.mean(auc_score(mf_model_bpr, train_sparse))\n",
    "test_auc = np.mean(auc_score(mf_model_bpr, test_sparse))\n",
    "print('AUC: train {:.2f}, test {:.2f}.'.format(train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56b90b",
   "metadata": {},
   "source": [
    "### Adjusting Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec7cfb",
   "metadata": {},
   "source": [
    "The number of embeddings, which determines the dimension of the features in the latent space, can be regulated by adjusting the n_components parameter. To observe the impact of the parameter on the model's effectiveness, we will first reduce the number to 5 and then elevate it to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b14fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init + fit\n",
    "mf_model_warp_2 = run_model(train, 5, 'warp', 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dba871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Metrics\n",
    "train_precision = np.mean(precision_at_k(mf_model_warp_2, train_sparse, k=10))\n",
    "test_precision = np.mean(precision_at_k(mf_model_warp_2, test_sparse, k=10))\n",
    "print('Precision: train {:.2f}, test {:.2f}.'.format(train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c49c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Metrics\n",
    "train_auc = auc_score(mf_model_warp_2, train_sparse).mean()\n",
    "test_auc = auc_score(mf_model_warp_2, test_sparse).mean()\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db140ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init + fit\n",
    "mf_model_warp_50 = run_model(train, 100, 'warp', 30, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Metrics\n",
    "train_precision = precision_at_k(mf_model_warp_50, train_sparse, k=10).mean()\n",
    "test_precision = precision_at_k(mf_model_warp_50, test_sparse, k=10).mean()\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d562604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC Metrics\n",
    "train_auc = auc_score(model=mf_model_warp_50, user_items=train_sparse).mean()\n",
    "test_auc = auc_score(model=mf_model_warp_50, user_items=test_sparse).mean()\n",
    "print(f'AUC: Train {train_auc:.2f}, Test {test_auc:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52737f33",
   "metadata": {},
   "source": [
    "In general, it seems that modifying the n_components attribute has minimal influence on the overall performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a6851",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a79edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train chosen model (WARP + 30 components) on interactions matrix.\n",
    "mf_model = run_model(interactions, 30, 'warp', 30, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561a777",
   "metadata": {},
   "source": [
    "### Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get item embeddings from the trained model\n",
    "item_embeddings = mf_model.item_embeddings\n",
    "item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample game vector\n",
    "item_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve name of game\n",
    "firstgameid = interactions.columns[0]\n",
    "games_dict[firstgameid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0648d5",
   "metadata": {},
   "source": [
    "### Examining Pair Similarity in Embedding Space with Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a61c4",
   "metadata": {},
   "source": [
    "We will perform vector similarity with two games we consider to be very similar, in this case `Call of Duty` and `Battlefield`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for both games\n",
    "mask = gamesdata['title'].isin(['Call of Duty', 'Battlefield'])\n",
    "gamesdata[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b323ccb",
   "metadata": {},
   "source": [
    "Check out vectors for COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_index = gamesdata[gamesdata['title']=='Call of Duty'].index.values[0]\n",
    "cod_vector = embeddings[cod_index]\n",
    "cod_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d63af60",
   "metadata": {},
   "source": [
    "Check out vectors for Battlefield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551801d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve game id for Battlefield\n",
    "bf_id = gamesdata.loc[gamesdata['title'] == 'Battlefield', 'id'].iloc[0]\n",
    "bf_index = np.where(interactions.columns == bf_id)[0][0]\n",
    "\n",
    "# Embeddings vector\n",
    "bf_vector = embeddings[bf_index]\n",
    "bf_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4abe1",
   "metadata": {},
   "source": [
    "Compute Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.euclidean(cod_vector, bf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86becf4a",
   "metadata": {},
   "source": [
    "#### We will now compare two games we consider to be 'different' in order to comprehend if this metric is accurate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56218423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter gamesdata to get only Call of Duty and Bloons TD 6\n",
    "game_titles = ['Counter-Strike', 'Bloons TD 6']\n",
    "game_data = gamesdata[gamesdata['title'].isin(game_titles)]\n",
    "game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4891858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve game id for Bloons\n",
    "bloons_id = gamesdata.loc[gamesdata['title']=='Bloons TD 6', 'id'].values[0]\n",
    "\n",
    "# Obtain index\n",
    "bloons_index = np.where(interactions.columns==bloons_id)[0][0]\n",
    "\n",
    "# Obtain embeddings vector\n",
    "bloons_vector = embeddings[bloons_index]\n",
    "bloons_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f708b",
   "metadata": {},
   "source": [
    "Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a800eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.euclidean(cod_vector, bloons_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0f8e8",
   "metadata": {},
   "source": [
    "Cosine Distances, comparing the two scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b00f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_cs_cod = distance.cosine(cod_vector, bf_vector)\n",
    "cosine_cs_bloons = distance.cosine(cod_vector, bloons_vector)\n",
    "\n",
    "print('Cos distance between COD and Battlefield: {:.2f}'.format(cosine_cs_lfd2))\n",
    "print('Cosine distance between COD and Bloons TD 6: {:.2f}'.format(cosine_cs_room))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471ee05",
   "metadata": {},
   "source": [
    "### Embedding Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = embeddings.shape[1]\n",
    "\n",
    "# Create instance\n",
    "kv = KeyedVectors(embedding_size)\n",
    "\n",
    "# Add game names and embeddings to kv\n",
    "for idx, game_id in enumerate(interactions.columns):\n",
    "    name = games_dict[games_dict['id']==game_id]['title'].values[0]\n",
    "    kv.add([name], [embeddings[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425434f",
   "metadata": {},
   "source": [
    "Check for games similar to `Call of Duty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0946726",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.most_similar('Call of Duty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7783378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to Battlefield\n",
    "kv.most_similar('Battlefield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1171b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to Bloons TD 6\n",
    "kv.most_similar('Bloons TD 6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad648e43",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similar_items(game_title, ax, num_items=5):\n",
    "    '''\n",
    "    Plots a horizontal bar chart of similar game items\n",
    "    Arguments:\n",
    "        - game_title, string representing the game title\n",
    "        - ax, the axes on which to plot the bar chart\n",
    "        - num_items (default=5), the number of similar items to plot\n",
    "    '''\n",
    "    similar_items = kv.most_similar(game_title, topn=num_items)[::-1]\n",
    "    y_pos = np.arange(len(similar_items))\n",
    "    item_similarities = [t[1] for t in similar_items]\n",
    "    ax.barh(y_pos, item_similarities)\n",
    "    left_margin = min(.6, min(item_similarities))\n",
    "    ax.set_xlim(right=1.0, left=left_margin)\n",
    "    \n",
    "    # Split long titles over multiple lines\n",
    "    item_labels = [textwrap.fill(t[0] , width=24) for t in similar_items]\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(item_labels)\n",
    "    ax.set_title(game_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfa7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of games to visualise similar items for\n",
    "games = ['Call of Duty', 'Battlefield', 'Bloons TD 6']\n",
    "\n",
    "# Create figure and set layout\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "gs = fig.add_gridspec(3, 2)\n",
    "\n",
    "# Loop through games and use plot_similar function \n",
    "for i, game in enumerate(games):\n",
    "    ax = fig.add_subplot(gs[i])\n",
    "    plot_similar(game, ax)\n",
    "\n",
    "# Add title and adjust layout\n",
    "fig.suptitle('Games and Their Most Similar Items', fontsize=16)\n",
    "fig.tight_layout(pad=2, rect=[0, 0, 1, 0.96])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3853821",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55225865",
   "metadata": {},
   "source": [
    "To visualize the embeddings, we will apply the t-SNE algorithm, which will transform the embeddings from a 30-dimensional space (determined by the number of components) into a 2-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TSNE object\n",
    "tsne = TSNE(n_components=2, metric='cosine', perplexity=30, n_iter=1000, random_state=0)\n",
    "\n",
    "# Fit and transform embeddings\n",
    "embeddings2d = tsne.fit_transform(embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f07c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New df with names and embeddings\n",
    "\n",
    "embeddingsdf = pd.DataFrame({'game': gameslist,\n",
    "                             'x': embeddings2d[:,0],\n",
    "                             'y': embeddings2d[:,1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496177d3",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.set_style('white')\n",
    "\n",
    "# Scatter points, set alpha low to make points translucent\n",
    "sns.scatterplot(x='x', y='y', data=embeddingsdf, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea30df",
   "metadata": {},
   "source": [
    "### Recommendations (User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for user with ID 5000\n",
    "user_id = user_dict['5000']\n",
    "interactions_user = interactions.loc[user_id,:]\n",
    "\n",
    "# Get the list of games that the user has interacted with\n",
    "known_user_likes = list(interactions_user[interactions_user>0].index)\n",
    "\n",
    "# Get the predicted score for each game\n",
    "scores = []\n",
    "for item_id in range(len(games_dict)):\n",
    "    if item_id not in known_user_likes:\n",
    "        score = mf_model.predict(user_id, item_id)\n",
    "        scores.append((item_id, score))\n",
    "\n",
    "# Sort scores and get top 5\n",
    "scores.sort(reverse=True, key=lambda x: x[1])\n",
    "topn_scores = scores[:5]\n",
    "\n",
    "# Convert game IDs to game names\n",
    "topn_games = []\n",
    "for score in topn_scores:\n",
    "    game_id = score[0]\n",
    "    topn_games.append(games_dict[game_id])\n",
    "\n",
    "# Show known games and recommendations\n",
    "if show_known:\n",
    "    print(f\"Known likes for user {user_id}:\")\n",
    "    for game in known_user_likes:\n",
    "        print(f\"- {games_dict[game]}\")\n",
    "if show_recs:\n",
    "    print(f\"Recommended games for user {user_id}:\")\n",
    "    for game in topn_games:\n",
    "        print(f\"- {game}\")\n",
    "\n",
    "# Return list of recommended games\n",
    "rec_list_u12 = topn_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a0412",
   "metadata": {},
   "source": [
    "### Recommendations (Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4eab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
